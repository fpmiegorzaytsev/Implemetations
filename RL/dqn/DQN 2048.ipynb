{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4ef6a-54c5-4f3d-a434-cde6abd0ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3, 4, 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1255177-1450-4d7d-8c29-ae34708a7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import matplotlib.pyplot as plt\n",
    "import flashbax as fbx\n",
    "import chex\n",
    "import warnings\n",
    "import jumanji\n",
    "from jumanji.wrappers import AutoResetWrapper\n",
    "import rlax\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "jax.device_count(), jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67587db1-b482-4ceb-b555-cebd72cb4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import anakin\n",
    "import dqn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841095f-951a-4adb-8089-fcd6b584e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EVAL_ITERS=25\n",
    "\n",
    "#training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 6.25e-05\n",
    "SEED = 42\n",
    "N_ENVS = 8\n",
    "BUFFER_SIZE = 10_000\n",
    "ROLLOUT_LEN = 512\n",
    "OPTIM_UPDATE_LEN = 64\n",
    "N_ITERATIONS = 20\n",
    "UPDATE_PERIOD = 10\n",
    "GAMMA = 0.99\n",
    "START_EPSILON = 1.0\n",
    "END_EPSILON = 0.1\n",
    "STEPS_EPSILON = 10_000\n",
    "\n",
    "#eval hyperparameters\n",
    "NUM_EVAL_EPISODES = 50\n",
    "MAX_EVAL_ITERS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3189413-16ea-4663-9ade-8862a93c2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = jumanji.make(\"Game2048-v1\")\n",
    "training_env = AutoResetWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69055bc4-a578-4da1-812e-7016d0d59024",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_devices, network, params, optim, opt_state, buffer, buffer_state, epsilon_schedule_fn, rng = utils.setup_experiment(\n",
    "    env=training_env,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=SEED,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    start_epsilon=START_EPSILON,\n",
    "    end_epsilon=END_EPSILON,\n",
    "    steps_epsilon=STEPS_EPSILON\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8eee1e-4fef-4b66-8945-7919dd115658",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, *rngs_env = jax.random.split(rng, n_devices * N_ENVS + 1)\n",
    "states, timesteps = jax.vmap(env.reset)(jnp.stack(rngs_env))\n",
    "reshape = lambda x: x.reshape((n_devices, N_ENVS) + x.shape[1:])\n",
    "states = jax.tree.map(reshape, states)\n",
    "timesteps = jax.tree.map(reshape, timesteps)\n",
    "\n",
    "params_state, opt_state, buffer_state, rngs_pv, rng = utils.broadcast_to_pv_shape(\n",
    "    n_devices, N_ENVS, params, opt_state, buffer_state, rng\n",
    ")\n",
    "\n",
    "learn_fn = anakin.get_learner_fn(\n",
    "    env=training_env,\n",
    "    rollout_len=ROLLOUT_LEN,\n",
    "    gamma=GAMMA,\n",
    "    buffer=buffer,\n",
    "    update_period=UPDATE_PERIOD,\n",
    "    n_iterations=N_ITERATIONS,\n",
    "    optim_update_len=OPTIM_UPDATE_LEN,\n",
    "    forward_fn=network.apply,\n",
    "    opt_update_fn=optim.update,\n",
    "    epsilon_schedule_fn=epsilon_schedule_fn\n",
    ")\n",
    "\n",
    "learn_fn = jax.pmap(learn_fn, axis_name='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69478c-49ca-47cd-be85-02b491109d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_one_episode(params, rng):\n",
    "  state, timestep = env.reset(rng)\n",
    "\n",
    "  def step_fn(val):\n",
    "    params, state, timestep, total_r, done, rng = val\n",
    "    rng, _ = jax.random.split(rng, 2)\n",
    "    obs = timestep.observation.board\n",
    "    action_mask = timestep.observation.action_mask\n",
    "    q_values = network.apply(params, jnp.expand_dims(obs, (0, 3))).squeeze(0)\n",
    "    q_values = utils.masked_fill(action_mask, q_values, -jnp.inf)\n",
    "    action = jnp.argmax(q_values)\n",
    "    next_state, next_timestep = env.step(state, action)\n",
    "    total_r += next_timestep.reward\n",
    "    return (params, next_state, next_timestep, total_r, next_timestep.last(), rng)\n",
    "\n",
    "  params, state, timestep, total_r, done, rng = jax.lax.while_loop(\n",
    "      lambda x: x[4] == False, step_fn, (params, state, timestep, 0, False, rng)\n",
    "  )\n",
    "  return params, total_r\n",
    "\n",
    "@jax.jit\n",
    "def eval(params, rng):\n",
    "  rngs = jax.random.split(rng, NUM_EVAL_EPISODES)\n",
    "  params = jax.tree.map(lambda x: x[0][0], params)\n",
    "  _, total_r = jax.lax.scan(eval_one_episode, params, rngs)\n",
    "  return jnp.mean(total_r), jnp.var(total_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8681e8-fd97-46ef-a292-83819f54e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_count = sum(x.size for x in jax.tree.leaves(params_state.online))\n",
    "# param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f44e64-3830-4403-b8bc-80cb58ce9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward = []\n",
    "bounds_avg_reward = []\n",
    "\n",
    "for iter in tqdm(range(TRAINING_EVAL_ITERS)):\n",
    "\n",
    "    # Train\n",
    "    params_state, opt_state, buffer_state, states, timesteps, rngs_pv = learn_fn(\n",
    "        params_state, opt_state, buffer_state, states, timesteps, rngs_pv\n",
    "    )\n",
    "    # params_state = jax.tree.map(lambda x: x.block_until_ready(), params_state) # wait for params to be ready so time is accurate.\n",
    "    # Eval\n",
    "    rng, rng_eval = jax.random.split(rng, 2)\n",
    "    total_r, total_r_var = eval(params_state.online, rng_eval)\n",
    "    avg_reward.append(total_r)\n",
    "    bounds_avg_reward.append(total_r_var)\n",
    "\n",
    "    # print(total_r_arr[:10])\n",
    "    clear_output(True)\n",
    "    print(f\"Mean Reward at iteration {iter}: {total_r}\")\n",
    "    print(f\"SE reward at iteration {iter}: {jnp.sqrt(total_r_var)}\")\n",
    "    print(f\"Epsilon at iteration {iter}: {epsilon_schedule_fn(params_state.update_count)[0][0]}\")\n",
    "    \n",
    "    plt.plot(avg_reward)\n",
    "    plt.plot(jnp.array(avg_reward) + jnp.sqrt(jnp.array(bounds_avg_reward)), linestyle='dashed', color='red')\n",
    "    plt.plot(jnp.array(avg_reward) - jnp.sqrt(jnp.array(bounds_avg_reward)), linestyle='dashed', color='red')\n",
    "    plt.title(\"Average reward each iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581d788-1f63-4713-a723-d3a908973e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "rng, rng_gif = jax.random.split(rng, 2)\n",
    "state, timestep = env.reset(rng_gif)\n",
    "params = jax.tree.map(lambda x: x[0][0], params_state.online)\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "    states.append(state)\n",
    "    obs = timestep.observation.board\n",
    "    action_mask = timestep.observation.action_mask\n",
    "    q_values = network.apply(params, jnp.expand_dims(obs, (0, 3))).squeeze(0)\n",
    "    q_values = utils.masked_fill(action_mask, q_values, -jnp.inf)\n",
    "    action = jnp.argmax(q_values)\n",
    "    state, timestep = env.step(state, action)\n",
    "    if timestep.last():\n",
    "        break\n",
    "\n",
    "env.animate(states, interval=150).save(\"./2048.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7eacb-f686-4f3b-97cb-20a4fc4fb098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e6a70-ef11-4e15-811c-77f91c681c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
